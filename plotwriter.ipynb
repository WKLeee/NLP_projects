{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import Embedding\n",
    "from numpy import array\n",
    "import time\n",
    "from ibm_watson import DiscoveryV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discovery_data(director, origin, year, genre):\n",
    "    movies = []\n",
    "    env_id = '",
    "    col_id = '163cf478-dc1f-4627-bed1-dace7928addd'\n",
    "    discovery = DiscoveryV1(\n",
    "        version = '2018-08-01',\n",
    "        iam_apikey = '",
    "        url = 'https://gateway.watsonplatform.net/discovery/api'\n",
    "    )\n",
    "    num = 100\n",
    "    sentence = director\n",
    "    filterParam = None\n",
    "    response1 = discovery.query(environment_id = env_id, collection_id = col_id, filter = filterParam, query = sentence, count = num)\n",
    "    res = response1.result['results']\n",
    "    for movie in res:\n",
    "        if movie['result_metadata']['score']>6:\n",
    "            movies.append({'title':movie['Title'],'plot':movie['Plot']})\n",
    "    filterParam = 'Origin:'+origin\n",
    "    sentence = genre\n",
    "    response1 = discovery.query(environment_id = env_id, collection_id = col_id, filter = filterParam, query = sentence, count = num)\n",
    "    res = response1.result['results']\n",
    "    for movie in res:\n",
    "        if movie['Title'] in str(movies):\n",
    "            pass\n",
    "        else:\n",
    "            movies.append({'title':movie['Title'],'plot':movie['Plot']})\n",
    "            \n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text\n",
    "\n",
    "def sequence_line(line, n):\n",
    "    sequences = list()\n",
    "    for i in range(n, len(line)) :\n",
    "        sequence = line[i-n: i]\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model (title, year, genre, director, origin):\n",
    "    ngram = 3\n",
    "    epochs_num = 1000\n",
    "    limit = 100\n",
    "    gen = genre\n",
    "    genre = genre.replace(' ','')\n",
    "    genres = genre.split(',')\n",
    "\n",
    "    filename = genre + \"_\" + str(ngram) + \"_\" + str(epochs_num) + \"_model.h5\"\n",
    "    data = []\n",
    "    f = open('movies.json','r')\n",
    "    while True:\n",
    "        s = f.readline()\n",
    "        if len(s) < 1:\n",
    "            break\n",
    "        data.append(json.loads(s))\n",
    "    f.close()\n",
    "    print(\"There are \"+str(len(data))+\" movies\")\n",
    "    \n",
    "    year_data = []\n",
    "    for a in data:\n",
    "        if a[\"Year\"]>=str(int(year)-5) and a[\"Year\"]<str(int(year)+5):\n",
    "            year_data.append(a)\n",
    "        \n",
    "    random.shuffle(year_data)\n",
    "    print(\"There are \"+year+\"+-5 \"+str(len(year_data))+\" movies\")\n",
    "\n",
    "    limited_data = []\n",
    "    for pre_data in data:\n",
    "        for g in genres:\n",
    "            if g in pre_data[\"Genre\"]:\n",
    "                limited_data.append(pre_data)\n",
    "\n",
    "    limited_data = limited_data[0:limit]\n",
    "    \n",
    "    disdata = get_discovery_data(director, origin, year, gen)\n",
    "    plots = [movie['Plot'] for movie in limited_data]\n",
    "    for d in disdata:\n",
    "        plots.append(d['plot'])\n",
    "    \n",
    "    print(\"Using {0} movie plots\".format(len(plots)))\n",
    "        \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(plots)\n",
    "    encoded = tokenizer.texts_to_sequences(plots)\n",
    "    \n",
    "    vocab_size = len(tokenizer.word_index)+1\n",
    "    print('vocab size = {0}'.format(vocab_size))\n",
    "    \n",
    "    print('processing {0}_grams'.format(ngram))\n",
    "    \n",
    "    sequences = list()\n",
    "    for line in encoded:\n",
    "        sequences.extend(sequence_line(line, ngram))\n",
    "\n",
    "    sequences = array(sequences)\n",
    "    x, y = sequences[:,0:-1], sequences[:,-1]\n",
    "    \n",
    "    model = None\n",
    "    title = title.replace(' ','')\n",
    "    filename = title + \"_\" + str(ngram) + \"_\" + str(epochs_num) + \"_model.h5\"\n",
    "    if(os.path.isfile(filename)):\n",
    "       model = load_model(filename)\n",
    "    if model is None:\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length = ngram-1))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(vocab_size, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(x,y, epochs=epochs_num, verbose=2, batch_size=256)\n",
    "        model.save(filename)\n",
    "        \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25538 movies\n",
      "There are 1997+-5 3075 movies\n",
      "Using 106 movie plots\n",
      "vocab size = 4864\n",
      "processing 3_grams\n",
      "Epoch 1/1000\n",
      " - 9s - loss: 8.2670 - acc: 0.0592\n",
      "Epoch 2/1000\n",
      " - 6s - loss: 6.8362 - acc: 0.0617\n",
      "Epoch 3/1000\n",
      " - 7s - loss: 6.6199 - acc: 0.0617\n",
      "Epoch 4/1000\n",
      " - 6s - loss: 6.5763 - acc: 0.0617\n",
      "Epoch 5/1000\n",
      " - 6s - loss: 6.5485 - acc: 0.0617\n",
      "Epoch 6/1000\n",
      " - 7s - loss: 6.5249 - acc: 0.0617\n",
      "Epoch 7/1000\n",
      " - 6s - loss: 6.5052 - acc: 0.0617\n",
      "Epoch 8/1000\n",
      " - 7s - loss: 6.4862 - acc: 0.0617\n",
      "Epoch 9/1000\n",
      " - 6s - loss: 6.4671 - acc: 0.0617\n",
      "Epoch 10/1000\n",
      " - 6s - loss: 6.4449 - acc: 0.0617\n",
      "Epoch 11/1000\n"
     ]
    }
   ],
   "source": [
    "year = '1997'\n",
    "genre = 'Drama, Romance'\n",
    "ngram = 3\n",
    "genre = genre.lower()\n",
    "title = 'Good Will Hunting'\n",
    "director = 'Gus Van Sant'\n",
    "origin = 'American'\n",
    "\n",
    "model, tokenizer = generate_model (title, year, genre, director, origin)\n",
    "print(generate_seq(model, tokenizer, ngram-1, 'A rich man', 24))\n",
    "print(generate_seq(model, tokenizer, ngram-1, 'He loves', 24))\n",
    "print(generate_seq(model, tokenizer, ngram-1, 'They married in', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
